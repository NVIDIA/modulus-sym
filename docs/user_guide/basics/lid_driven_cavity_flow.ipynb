{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8742d4c2",
   "metadata": {},
   "source": [
    "# Introductory Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50df614",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This tutorial steps through the process of solving a 2D flow for the Lid Driven Cavity (LDC) example using physics-informed neural networks (PINNs) from NVIDIA Modulus Sym framework. In this tutorial, you will learn how to:\n",
    "\n",
    "1. Generate a 2D geometry using Modulus Sym' geometry module\n",
    "2. Set up the boundary conditions\n",
    "3. Select the flow equations to be solved - create appropriate equation nodes\n",
    "4. Interpret the different losses and tune the network \n",
    "5. Do basic post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b647ea",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "The tutorial assumes that you have successfully downloaded the Modulus Sym repository and examples. Here we will develop the example step by step interactively. The python script version of this problem can be found at `examples/ldc/ldc_2d.py`. Before starting to run the examples, please copy the folders `examples/ldc/conf` and `examples/ldc/openfoam` to your working directory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38a64d",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "\n",
    "The geometry for the problem is shown in figure below. The domain is a square cavity whose sides are each $0.1$ m long. We define the center of the square as the origin of a Euclidean coordinate frame, with the $x$ direction going left to right (increasing to the right), and the $y$ direction going down to up (increasing up). The left, right, and bottom sides of the square domain are stationary walls, while the top wall moves in the x direction to the right at $1$.\n",
    "\n",
    "<center>\n",
    "    <img src=\"../../images/user_guide/ldc.png\" width=\"300\" height=\"300\" style=\"margin:auto\"/>\n",
    "    <figcaption>Lid driven cavity geometry</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70006936",
   "metadata": {},
   "source": [
    "An important quantity for fluid flow problems is the Reynolds number, a unitless quantity that helps describe whether flow will be more laminar (sheet-like) or turbulent. The Reynolds number is a function of the flow speed, the “characteristic length” of the problem (in this case, the cavity height), and the kinematic velocity (which we will define below). For this problem, we have chosen these quantities so that the Reynolds number is $10$, indicating a more laminar flow.\n",
    "\n",
    "\n",
    "We first summarize the key concepts and how they relate to Modulus Sym’ features. (For a more detailed discussion, please see [Basic methodology](../theory/phys_informed.rst#basic-methodology).) Solving any physics-driven simulation that is defined by differential equations requires information about the domain of the problem and its governing equations and boundary conditions. Users can define the domain using Modulus Sym’ Constructive Solid Geometry (CSG) module, the STL module, or data from external sources like text files in comma-separated values (CSV) format, NumPy files, or HDF5 files. Once you have this geometry or point cloud, it can be sub-sampled into two sets: points on the boundaries to satisfy the boundary conditions, and interior regions to minimize the PDE/ODE residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1256029",
   "metadata": {},
   "source": [
    "### Load Hydra\n",
    "\n",
    "Hydra configuration files are at the heart of using Modulus Sym. Each configuration file is a text file in YAML format. Most of the Modulus Sym' features can be customized through Hydra. More information can be found in [Modulus Sym Configuration](../features/configuration.rst). \n",
    "\n",
    "The config file is saved in `/examples/ldc/conf/config.yaml` which can be loaded using Modulus Sym' ``compose()`` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a1f893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "  max_steps: 10000\n",
      "  grad_agg_freq: 1\n",
      "  rec_results_freq: 1000\n",
      "  rec_validation_freq: 1000\n",
      "  rec_inference_freq: 2000\n",
      "  rec_monitor_freq: 1000\n",
      "  rec_constraint_freq: 2000\n",
      "  save_network_freq: 1000\n",
      "  print_stats_freq: 100\n",
      "  summary_freq: 1000\n",
      "  amp: false\n",
      "  amp_dtype: float16\n",
      "  ntk:\n",
      "    use_ntk: false\n",
      "    save_name: null\n",
      "    run_freq: 1000\n",
      "graph:\n",
      "  func_arch: true\n",
      "  func_arch_allow_partial_hessian: true\n",
      "stop_criterion:\n",
      "  metric: null\n",
      "  min_delta: null\n",
      "  patience: 50000\n",
      "  mode: min\n",
      "  freq: 1000\n",
      "  strict: false\n",
      "profiler:\n",
      "  profile: false\n",
      "  start_step: 0\n",
      "  end_step: 100\n",
      "  name: nvtx\n",
      "network_dir: outputs\n",
      "initialization_network_dir: ''\n",
      "save_filetypes: vtk\n",
      "summary_histograms: false\n",
      "jit: true\n",
      "jit_use_nvfuser: true\n",
      "jit_arch_mode: only_activation\n",
      "jit_autograd_nodes: false\n",
      "cuda_graphs: true\n",
      "cuda_graph_warmup: 20\n",
      "find_unused_parameters: false\n",
      "broadcast_buffers: false\n",
      "device: ''\n",
      "debug: false\n",
      "run_mode: train\n",
      "arch:\n",
      "  fully_connected:\n",
      "    arch_type: fully_connected\n",
      "    input_keys: ???\n",
      "    output_keys: ???\n",
      "    detach_keys: ???\n",
      "    scaling: null\n",
      "    layer_size: 512\n",
      "    nr_layers: 6\n",
      "    skip_connections: false\n",
      "    activation_fn: silu\n",
      "    adaptive_activations: false\n",
      "    weight_norm: true\n",
      "models: ???\n",
      "loss:\n",
      "  _target_: modulus.loss.aggregator.Sum\n",
      "  weights: null\n",
      "optimizer:\n",
      "  _params_:\n",
      "    compute_gradients: adam_compute_gradients\n",
      "    apply_gradients: adam_apply_gradients\n",
      "  _target_: torch.optim.Adam\n",
      "  lr: 0.001\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "  eps: 1.0e-08\n",
      "  weight_decay: 0.0\n",
      "  amsgrad: false\n",
      "scheduler:\n",
      "  _target_: custom\n",
      "  _name_: tf.ExponentialLR\n",
      "  decay_rate: 0.95\n",
      "  decay_steps: 4000\n",
      "batch_size:\n",
      "  TopWall: 1000\n",
      "  NoSlip: 1000\n",
      "  Interior: 4000\n",
      "custom: ???\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import modulus.sym\n",
    "from modulus.sym.hydra import to_yaml\n",
    "from modulus.sym.hydra.utils import compose\n",
    "from modulus.sym.hydra.config import Modulus SymConfig\n",
    "\n",
    "cfg = compose(config_path=\"conf\", config_name=\"config\")\n",
    "cfg.network_dir = 'outputs'    # Set the network directory for checkpoints\n",
    "print(to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd46929",
   "metadata": {},
   "source": [
    "### Create Nodes\n",
    "\n",
    "#### Create a PDE node\n",
    "\n",
    "The LDC example uses the 2D steady-state incompressible *Navier-Stokes equations* to model fluid flow. The Navier-Stokes equations are a system of coupled partial differential equations (PDEs) that describe the flow velocity and pressure at every point in the domain. The two independent variables of the problem represent position: $x$ and $y$.\n",
    "We will solve for three variables: $u$ is the flow velocity in the $x$ direction, $v$ is the flow velocity in the $y$ direction, and $p$ is the pressure at a given point. The incompressible Navier-Stokes equations have two parameters: the *kinematic velocity* $\\nu$, and the *density* of the fluid $\\rho$. Modulus Sym can solve problems with nonconstant $\\nu$ and $\\rho$, but we leave them constant to keep this example simple.\n",
    "\n",
    "If we assume that the density is a constant and rescale so that $\\rho$ is 1, then the equations take the following form.\n",
    "\n",
    "\\begin{aligned}\n",
    "   \\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} &= 0\\\\\n",
    "   u\\frac{\\partial u}{\\partial x} + v\\frac{\\partial u}{\\partial y} &= -\\frac{\\partial p}{\\partial x} + \\nu \\left(\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right)\\\\\n",
    "   u\\frac{\\partial v}{\\partial x} + v\\frac{\\partial v}{\\partial y} &= -\\frac{\\partial p}{\\partial y} + \\nu \\left(\\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2} \\right)\n",
    "\\end{aligned}\n",
    "\n",
    "The first equation, the *continuity* equation, expresses that the flow is incompressible (mathematically, that the flow is \"divergence free\").\n",
    "The second and third equations are the *momentum* or momentum balance equations.\n",
    "\n",
    "Lets call the ``NavierStokes`` function to tell Modulus Sym that we want to solve the Navier-Stokes equations. We set the kinematic viscosity ``nu=0.01`` and the density ``rho=1.0``. We set ``time=False`` because this is a steady-state problem (time is not a variable), and ``dim=2`` because this is a 2D problem. The function returns a list of ``Node`` objects, which we will need to keep for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d69b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.eq.pdes.navier_stokes import NavierStokes\n",
    "\n",
    "# make list of nodes to unroll graph on\n",
    "ns = NavierStokes(nu=0.01, rho=1.0, dim=2, time=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff22bb0",
   "metadata": {},
   "source": [
    "#### Create a Neural Network Node\n",
    "\n",
    "We will create a neural network to approximate the solution of the Navier-Stokes equations for the given boundary conditions. The neural network will have two inputs $x, y$\n",
    "and three outputs $u, v, p$.\n",
    "\n",
    "Modulus Sym comes with several different neural network architectures. Different architectures may perform better or worse on different problems. \"Performance\" may refer to any combination of time to solution, total memory use, or efficiency when scaling out on a cluster of parallel computers. For simplicity and not necessarily for best performance,\n",
    "we will use a fully connected neural network in this example.\n",
    "\n",
    "We create the neural network by calling Modulus Sym' ``instantiate_arch`` function. The ``input_keys`` argument specifies the inputs, and the ``output_keys`` argument the outputs. We specify each input or output as a ``Key`` object whose string label is the same as the label of the corresponding ``Symbol`` object. A ``Key`` class is used for describing inputs and outputs used for graph unroll/evaluation. The most basic key is just a string that is used to represent the name of inputs or outputs of the model.\n",
    "\n",
    "Setting ``cfg=cfg.arch.fully_connected`` selects the default ``FullyConnectedArch`` neural network architecture. This tells Modulus Sym to use a multi-layer perceptron (MLP) neural network with 6 layers. Each layer contains 512 perceptrons and uses the \"swish\" (also known as SiLU) activation function.\n",
    "\n",
    "All these parameters -- e.g., the number of layers, the number of perceptrons in each layer, and the activation function to use for each layer -- are user configurable.\n",
    "For this example, the default values are known to work, though they might not be optimal.\n",
    "\n",
    "Let's create the neural network and add finally add it to the ``nodes`` list. We will use this list of nodes to pass to different constraints that need to be satisfied for this problem. The constraints include equations, residuals, and boundary conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a586a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.hydra import instantiate_arch\n",
    "from modulus.sym.key import Key\n",
    "\n",
    "flow_net = instantiate_arch(\n",
    "    input_keys=[Key(\"x\"), Key(\"y\")],\n",
    "    output_keys=[Key(\"u\"), Key(\"v\"), Key(\"p\")],\n",
    "    cfg=cfg.arch.fully_connected,\n",
    ")\n",
    "nodes = ns.make_nodes() + [flow_net.make_node(name=\"flow_network\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c48d973",
   "metadata": {},
   "source": [
    "### Create Geometry\n",
    "\n",
    "We now create the geometry for the LDC example problem. “Geometry” refers to the physical shapes of the domain and its boundaries. The geometry can be created either before or after creating the PDE and the neural network. Modulus Sym lets users create the geometry in different ways. For this example, we will use Modulus Sym’ CSG module. The CSG module supports a wide variety of primitive shapes. In 2D, these shapes include rectangles, circles, triangles, infinite channels, and lines. In 3D, they include spheres, cones, cuboids, infinite channels, planes, cylinders, tori, tetrahedra, and triangular prisms. Users can construct more complicated geometries by combining these primitives using operations like addition, subtraction, and intersection. Please see [Geometry Modules](../features/csg_and_tessellated_module.rst) for more details.\n",
    "\n",
    "We begin by defining the required symbolic variables for the geometry and then generating the 2D square geometry by using the `Rectangle` geometry object. In Modulus Sym, a `Rectangle` is defined using the coordinates for two opposite corner points. The symbolic variable will be used to later sub-sample the geometry to create different boundaries, interior regions, etc. while defining constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89cb2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Symbol, Eq, Abs\n",
    "from modulus.sym.geometry.primitives_2d import Rectangle\n",
    "\n",
    "# make geometry\n",
    "height = 0.1\n",
    "width = 0.1\n",
    "x, y = Symbol(\"x\"), Symbol(\"y\")\n",
    "rec = Rectangle((-width / 2, -height / 2), (width / 2, height / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0a786",
   "metadata": {},
   "source": [
    "### Add Constraints\n",
    "\n",
    "#### Setting up the Domain \n",
    "\n",
    "The ``Domain`` object contains the PDE and its boundary conditions, as well as any other utilities used for post-processing. Modulus Sym calls the PDE and its boundary conditions \"constraints\". The PDE, in particular, constrains the outputs on the interior of the domain. The ``Domain`` and the configuration options both in turn will be used to create an instance of the ``Solver`` class.\n",
    "\n",
    "Let's create a ``Domain`` object. We will add constraints to this domain separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ca97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.domain import Domain\n",
    "\n",
    "# make ldc domain\n",
    "ldc_domain = Domain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7967e679",
   "metadata": {},
   "source": [
    "Apart from constraints, you can add various other utilities to the ``Domain`` such as monitors, validation data, or points on which to do inference. Each of these is covered in detail in this example.\n",
    "\n",
    "Adding constraints to the ``Domain`` can be thought of as adding specific constraints to the neural network optimization problem. For this physics-driven problem, these constraints are the boundary conditions and equation residuals. The goal is to satisfy the boundary conditions exactly, and have the interior (PDE) residual (a measure of the error) go to zero. The constraints can be specified within Modulus Sym using classes like ``PointwiseBoundaryConstrant`` and ``PointwiseInteriorConstraint``.\n",
    "Modulus Sym then constructs a *loss function* -- a measure of the neural network's approximation error -- from the constraints. By default, Modulus Sym will use L2 (sum of squares) loss, but it is possible to change this.\n",
    "\n",
    "The optimizer will train the neural network by minimizing the loss function. This way of specifying the constraints is called *soft constraints*. In what follows, we will explain how to specify the constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601792d9",
   "metadata": {},
   "source": [
    "#### Boundary Constraints\n",
    "\n",
    "To create a boundary condition constraint in Modulus Sym, first sample the points on that part of the geometry, then specify the nodes you want to evaluate on those points, and finally assign them the desired true values. \"Sample the points\" refers to creating a set of points that live on that part of the geometry. The \"nodes\" here refer to the list of PDE and neural network nodes that we created before. \n",
    "\n",
    "Some examples and documentation will use in place of \"evaluate,\" a phrase like \"unroll the nodes\" on \"unroll the graph on the list of nodes.\" \"Unroll\" means \"construct the computational graph on the list of nodes.\" That last point calls for some elaboration. Each ``Constraint`` takes in a list of ``Node``s with each ``Node`` having a list of input and output ``Key``s. The inputs to the ``Constraint`` are just the coordinates ($x$ and $y$ in this example) and the output is a loss value.  As part of computing the loss value, the ``Constraint`` might have a model that computes intermediate quantities. In this example, the interior ``Constraint`` requires derivatives of the output with respect to the input in order to compute residuals of the continuity and momentum equations. The loss value comes from the sum of squares of those residuals. Internally, Modulus Sym needs to figure out how to evaluate the model and the PDE and compute the required intermediate quantities (the derivatives, for example). This amounts to connecting nodes (quantities to compute) with edges (methods for combining quantities to compute other quantities) to create a \"computational graph\" for that ``Constraint``. This process is what we typically refer to as \"unrolling the graph\".\n",
    "\n",
    "We sample a boundary by using a ``PointwiseBoundaryConstraint`` object. This will sample the entire boundary of the geometry you specify in the ``geometry`` argument when creating the object. For this example, once you set ``geometry=rec``, all the sides of the rectangle are sampled. A particular boundary of the geometry can be sub-sampled by using the ``criteria`` argument. This can be any symbolic function defined using the ``sympy`` library. For example, to sample the top wall, wet set ``criteria=Eq(y,height/2)``.\n",
    "\n",
    "The constraint's ``outvar`` argument specifies the desired values for the boundary condition as a dictionary. For example, ``outvar={\"u\": 1.0, \"v\": 0.0}`` says that the value of the ``u`` output is 1.0 on that boundary, and the value of the ``v`` output is 0.0 on that boundary. The constraint's ``batch_size`` argument specifies the number of points to sample on each boundary.\n",
    "\n",
    "A few things to note: \n",
    "\n",
    " - The ``criteria`` argument is optional. With no ``criteria``, all the boundaries in the geometry are sampled.\n",
    "\n",
    " - The network directory will only show the points sampled in a single batch. However, the total points used in the training can be computed by further multiplying the batch size by ``batch_per_epoch`` parameter. The default value of this is set to 1000. In the example above, the total points sampled on the Top BC will be $1000 \\times 1000 = 1000000$.\n",
    "\n",
    "For the LDC problem, we define the top wall with a $u$ velocity equal to $1 m/s$ in the $+ve$ x-direction, and define the velocity on all other walls as stationary ($u,v = 0$).\n",
    "Below figure shows that this can give rise to sharp discontinuities, wherein the $u$ velocity jumps sharply from $0$ to $1.0$. As outlined in the theory explanation [Spatial Weighting of Losses (SDF Weighting)](../theory/recommended_practices.rst#spatial-weighting-of-losses-sdf-weighting), this sharp discontinuity can be avoided by specifying the weighting for this boundary such that the weight of the loss varies continuously and is $0$ on the boundaries.\n",
    "\n",
    "\n",
    "You can use the function $1.0 - 20.0|x|$ as shown in the figure for this purpose. Similar to the advantages of weighting losses for equations ([see](../theory/recommended_practices.rst#spatial-weighting-of-losses-sdf-weighting)), eliminating such discontinuities speeds up convergence and improves accuracy.\n",
    "\n",
    "Weights to any variables can be specified as an input to the ``lambda_weighting`` parameter.\n",
    "\n",
    "<center>\n",
    "    <img src=\"../../images/user_guide/ldc_lambda.png\" width=\"800\" style=\"margin:auto\"/>\n",
    "    <figcaption>Weighting the sharp discontinuities in the boundary condition</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380182d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.domain.constraint import PointwiseBoundaryConstraint\n",
    "\n",
    "# top wall\n",
    "top_wall = PointwiseBoundaryConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=rec,\n",
    "    outvar={\"u\": 1.0, \"v\": 0},\n",
    "    batch_size=cfg.batch_size.TopWall,\n",
    "    lambda_weighting={\"u\": 1.0 - 20 * Abs(x), \"v\": 1.0},  # weight edges to be zero\n",
    "    criteria=Eq(y, height / 2),\n",
    ")\n",
    "ldc_domain.add_constraint(top_wall, \"top_wall\")\n",
    "\n",
    "# no slip\n",
    "no_slip = PointwiseBoundaryConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=rec,\n",
    "    outvar={\"u\": 0, \"v\": 0},\n",
    "    batch_size=cfg.batch_size.NoSlip,\n",
    "    criteria=y < height / 2,\n",
    ")\n",
    "ldc_domain.add_constraint(no_slip, \"no_slip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb9ca2",
   "metadata": {},
   "source": [
    "#### PDE Constraints\n",
    "\n",
    "This example problem's PDEs need to be enforced on all the points in the interior of the geometry to achieve the desired solution. Analogously to the boundaries, this requires\n",
    "first sampling the points inside the required geometry, then specifying the nodes to evaluate on those points, and finally assigning them the true values that you want for them.\n",
    "\n",
    "We use the ``PointwiseInteriorConstraint`` class to sample points in the interior of a geometry. Its ``outvar`` argument specifies the equations to solve as a dictionary.\n",
    "For the 2D LDC case, the continuity equation and the momentum equations in $x$ and $y$ directions are needed. Therefore, the dictionary has keys for ``'continuity'``, ``'momentum_x'`` and ``'momentum_y'``. Each of these keys has the corresponding value 0. This represents the desired residual for these keys at the chosen points (in this case, the entire interior of the LDC geometry). A nonzero value is allowed, and behaves as a custom forcing or source term. More examples of this can be found in the later chapters of this User Guide. To see how the equation keys are defined, you can look at the Modulus Sym source or see the API documentation (``modulus/eq/pdes/navier_stokes.py``).\n",
    "\n",
    "As an example, the definition of ``'continuity'`` is presented here. \n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "   ...\n",
    "   # set equations\n",
    "   self.equations = {}\n",
    "   self.equations['continuity'] = rho.diff(t) + (rho*u).diff(x) + (rho*v).diff(y) + (rho*w).diff(z)\n",
    "   ...\n",
    "```\n",
    "\n",
    "The equations below show the part of the loss function corresponding to each of the three equations in the system of PDEs.\n",
    "\n",
    "\\begin{align}\n",
    "L_{continuity}= \\frac{V}{N} \\sum_{i=0}^{N} ( 0 - continuity(x_i,y_i))^2\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "L_{momentum_{x}}= \\frac{V}{N} \\sum_{i=0}^{N} ( 0 - momentum_{x}(x_i,y_i))^2\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "L_{momentum_{y}}= \\frac{V}{N} \\sum_{i=1}^{n} (0 - momentum_{y}(x_i, y_i))^2\n",
    "\\end{align}\n",
    "\n",
    "The ``bounds`` parameter determines the range for sampling the values for variables $x$ and $y$. The ``lambda_weighting`` parameter is used to determine the weights for different losses. In this problem, you will weight each equation at each point by its distance from the boundary by using the Signed Distance Field (SDF) of the geometry. This implies that the points away from the boundary have a larger weight compared to the ones closer to the boundary. This weighting leads to faster convergence since it avoids discontinuities at the boundaries (see section [Spatial Weighting of Losses (SDF Weighting)](../theory/recommended_practices.rst#spatial-weighting-of-losses-sdf-weighting)).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "The ``lambda_weighting`` parameter is optional. If not specified, the loss for each equation/boundary variable at each point is weighted equally.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d293566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.domain.constraint import PointwiseInteriorConstraint\n",
    "\n",
    "# interior\n",
    "interior = PointwiseInteriorConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=rec,\n",
    "    outvar={\"continuity\": 0, \"momentum_x\": 0, \"momentum_y\": 0},\n",
    "    batch_size=cfg.batch_size.Interior,\n",
    "    lambda_weighting={\n",
    "        \"continuity\": Symbol(\"sdf\"),\n",
    "        \"momentum_x\": Symbol(\"sdf\"),\n",
    "        \"momentum_y\": Symbol(\"sdf\"),\n",
    "    },\n",
    ")\n",
    "ldc_domain.add_constraint(interior, \"interior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f90160",
   "metadata": {},
   "source": [
    "### Create Validators\n",
    "\n",
    "\"Validation\" means comparing the approximate solution computed by Modulus Sym with data representing results obtained by some other method. The results could come from any combination of simulation or experiment. This section shows how to set up such a validation domain in Modulus Sym. Here, we use results from OpenFOAM, an open-source computational fluid dynamics (CFD) solver that discretizes the Navier-Stokes equations on a mesh and solves them using nonlinear and linear solvers not based on neural networks. Results can be imported into Modulus Sym from any of various standard file formats, including ``.csv``, ``.npz``, or ``.vtk``.\n",
    "\n",
    "Modulus Sym requires that the data be converted into a dictionary of NumPy variables for input and output. For a ``.csv`` file, this can be done using the ``csv_to_dict`` function.\n",
    "\n",
    "The validation data is then added to the domain using ``PointwiseValidator``. The dictionary of generated NumPy arrays for input and output variables is used as an input. \"Validation\" means comparing the approximate solution computed by Modulus Sym with data representing results obtained by some other method. The results could come from any combination of simulation or experiment. This section shows how to set up such a validation domain in Modulus Sym. Here, we use results from OpenFOAM, an open-source computational fluid dynamics (CFD) solver that discretizes the Navier-Stokes equations on a mesh and solves them using nonlinear and linear solvers not based on neural networks. Results can be imported into Modulus Sym from any of various standard file formats, including ``.csv``, ``.npz``, or ``.vtk``. Modulus Sym requires that the data be converted into a dictionary of NumPy variables for input and output. For a ``.csv`` file, this can be done using the ``csv_to_dict`` function. The validation data is then added to the domain using ``PointwiseValidator``. The dictionary of generated NumPy arrays for input and output variables is used as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667fb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.sym.hydra import to_absolute_path\n",
    "from modulus.sym.domain.validator import PointwiseValidator\n",
    "from modulus.sym.utils.io import (\n",
    "    csv_to_dict,\n",
    "    ValidatorPlotter,\n",
    "    InferencerPlotter,\n",
    ")\n",
    "    \n",
    "# add validator\n",
    "mapping = {\"Points:0\": \"x\", \"Points:1\": \"y\", \"U:0\": \"u\", \"U:1\": \"v\", \"p\": \"p\"}\n",
    "openfoam_var = csv_to_dict(\n",
    "    to_absolute_path(\"openfoam/cavity_uniformVel0.csv\"), mapping\n",
    ")\n",
    "openfoam_var[\"x\"] += -width / 2  # center OpenFoam data\n",
    "openfoam_var[\"y\"] += -height / 2  # center OpenFoam data\n",
    "openfoam_invar_numpy = {\n",
    "    key: value for key, value in openfoam_var.items() if key in [\"x\", \"y\"]\n",
    "}\n",
    "openfoam_outvar_numpy = {\n",
    "    key: value for key, value in openfoam_var.items() if key in [\"u\", \"v\"]\n",
    "}\n",
    "openfoam_validator = PointwiseValidator(\n",
    "    nodes=nodes,\n",
    "    invar=openfoam_invar_numpy,\n",
    "    true_outvar=openfoam_outvar_numpy,\n",
    "    batch_size=1024,\n",
    "    plotter=ValidatorPlotter(),\n",
    ")\n",
    "ldc_domain.add_validator(openfoam_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e1786",
   "metadata": {},
   "source": [
    "### Put everything together: Solver and Training\n",
    "\n",
    "We create a ``Solver`` with the configuration options ``cfg`` and the ``Domain`` that we just finished setting up. We then call the ``solve()`` method on the ``Solver`` to solve the problem.\n",
    "\n",
    "You are now ready to solve the CFD simulation using Modulus Sym' neural network solver. Running the below code block will start the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc00c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make the logging work in the jupyter cells\n",
    "# execute this cell only once\n",
    "import logging\n",
    "logging.getLogger('modulus').addHandler(logging.StreamHandler())\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c6f4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "attempting to restore from: /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "\u001b[32mSuccess loading optimizer: \u001b[0m/examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs/optim_checkpoint.0.pth\n",
      "\u001b[32mSuccess loading model: \u001b[0m/examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs/flow_network.0.pth\n",
      "[step:          0] saved constraint results to outputs\n",
      "[step:          0] record constraint batch time:  2.129e-01s\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeac3a4880>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeac2b3640>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeac2329a0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeac143700>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeac0c4880>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeac046790>\n",
      "[step:          0] saved validator results to outputs\n",
      "[step:          0] record validators time:  6.496e+00s\n",
      "[step:          0] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:          0] loss:  4.459e-02\n",
      "Attempting cuda graph building, this may take a bit...\n",
      "[step:        100] loss:  1.060e-02, time/iteration:  1.354e+02 ms\n",
      "[step:        200] loss:  5.619e-03, time/iteration:  1.309e+02 ms\n",
      "[step:        300] loss:  4.002e-03, time/iteration:  1.312e+02 ms\n",
      "[step:        400] loss:  2.410e-03, time/iteration:  1.310e+02 ms\n",
      "[step:        500] loss:  2.062e-03, time/iteration:  1.314e+02 ms\n",
      "[step:        600] loss:  1.881e-03, time/iteration:  1.312e+02 ms\n",
      "[step:        700] loss:  1.556e-03, time/iteration:  1.313e+02 ms\n",
      "[step:        800] loss:  1.267e-03, time/iteration:  1.310e+02 ms\n",
      "[step:        900] loss:  1.047e-03, time/iteration:  1.317e+02 ms\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeaf3fb340>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea0e7a430>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea0df94f0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea0ce4910>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea0c692b0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea0be7310>\n",
      "[step:       1000] saved validator results to outputs\n",
      "[step:       1000] record validators time:  6.486e+00s\n",
      "[step:       1000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       1000] loss:  1.032e-03, time/iteration:  2.104e+02 ms\n",
      "[step:       1100] loss:  7.767e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       1200] loss:  8.392e-04, time/iteration:  1.313e+02 ms\n",
      "[step:       1300] loss:  9.278e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       1400] loss:  8.906e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       1500] loss:  4.929e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       1600] loss:  6.215e-04, time/iteration:  1.314e+02 ms\n",
      "[step:       1700] loss:  5.576e-04, time/iteration:  1.321e+02 ms\n",
      "[step:       1800] loss:  4.529e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       1900] loss:  4.336e-04, time/iteration:  1.312e+02 ms\n",
      "[step:       2000] saved constraint results to outputs\n",
      "[step:       2000] record constraint batch time:  1.674e-01s\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeaf430af0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea0a2cc40>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea09a8bb0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea089d160>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea08d9580>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea0794dc0>\n",
      "[step:       2000] saved validator results to outputs\n",
      "[step:       2000] record validators time:  6.527e+00s\n",
      "[step:       2000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       2000] loss:  9.650e-04, time/iteration:  2.119e+02 ms\n",
      "[step:       2100] loss:  4.094e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       2200] loss:  4.142e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       2300] loss:  4.741e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       2400] loss:  4.093e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       2500] loss:  5.639e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       2600] loss:  6.334e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       2700] loss:  4.104e-04, time/iteration:  1.316e+02 ms\n",
      "[step:       2800] loss:  5.952e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       2900] loss:  2.530e-04, time/iteration:  1.312e+02 ms\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea06628e0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea05dca30>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea05549a0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea04c0a90>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea04f1c40>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea03c1af0>\n",
      "[step:       3000] saved validator results to outputs\n",
      "[step:       3000] record validators time:  6.479e+00s\n",
      "[step:       3000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       3000] loss:  3.451e-04, time/iteration:  2.101e+02 ms\n",
      "[step:       3100] loss:  3.503e-04, time/iteration:  1.312e+02 ms\n",
      "[step:       3200] loss:  3.614e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       3300] loss:  3.076e-04, time/iteration:  1.314e+02 ms\n",
      "[step:       3400] loss:  2.100e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       3500] loss:  2.656e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       3600] loss:  2.769e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       3700] loss:  3.238e-04, time/iteration:  1.313e+02 ms\n",
      "[step:       3800] loss:  2.436e-04, time/iteration:  1.313e+02 ms\n",
      "[step:       3900] loss:  2.626e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       4000] saved constraint results to outputs\n",
      "[step:       4000] record constraint batch time:  1.351e-01s\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeaf4fbc40>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea01fbd90>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea0173d90>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbea00681c0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97fe1250>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97f482b0>\n",
      "[step:       4000] saved validator results to outputs\n",
      "[step:       4000] record validators time:  6.798e+00s\n",
      "[step:       4000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       4000] loss:  3.339e-04, time/iteration:  2.152e+02 ms\n",
      "[step:       4100] loss:  2.094e-04, time/iteration:  1.332e+02 ms\n",
      "[step:       4200] loss:  3.291e-04, time/iteration:  1.330e+02 ms\n",
      "[step:       4300] loss:  2.815e-04, time/iteration:  1.329e+02 ms\n",
      "[step:       4400] loss:  2.006e-04, time/iteration:  1.327e+02 ms\n",
      "[step:       4500] loss:  2.601e-04, time/iteration:  1.315e+02 ms\n",
      "[step:       4600] loss:  2.266e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       4700] loss:  3.141e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       4800] loss:  2.861e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       4900] loss:  4.685e-04, time/iteration:  1.311e+02 ms\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97dff520>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97dfa640>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97d76640>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97c62610>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97be15b0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97b62580>\n",
      "[step:       5000] saved validator results to outputs\n",
      "[step:       5000] record validators time:  6.424e+00s\n",
      "[step:       5000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       5000] loss:  3.729e-04, time/iteration:  2.088e+02 ms\n",
      "[step:       5100] loss:  2.114e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       5200] loss:  3.072e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       5300] loss:  3.220e-04, time/iteration:  1.312e+02 ms\n",
      "[step:       5400] loss:  3.325e-04, time/iteration:  1.306e+02 ms\n",
      "[step:       5500] loss:  2.829e-04, time/iteration:  1.307e+02 ms\n",
      "[step:       5600] loss:  3.112e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       5700] loss:  2.745e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       5800] loss:  3.049e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       5900] loss:  1.759e-04, time/iteration:  1.312e+02 ms\n",
      "[step:       6000] saved constraint results to outputs\n",
      "[step:       6000] record constraint batch time:  1.318e-01s\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeaf565c40>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe979a1d90>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97919d00>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97804d60>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe978b6e80>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97708d00>\n",
      "[step:       6000] saved validator results to outputs\n",
      "[step:       6000] record validators time:  6.354e+00s\n",
      "[step:       6000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       6000] loss:  5.738e-04, time/iteration:  2.098e+02 ms\n",
      "[step:       6100] loss:  1.562e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       6200] loss:  1.249e-04, time/iteration:  1.307e+02 ms\n",
      "[step:       6300] loss:  1.612e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       6400] loss:  2.176e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       6500] loss:  1.494e-04, time/iteration:  1.294e+02 ms\n",
      "[step:       6600] loss:  1.570e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       6700] loss:  1.579e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       6800] loss:  1.984e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       6900] loss:  1.135e-04, time/iteration:  1.308e+02 ms\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe975ca8e0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97544a30>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe974bea60>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97426be0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe973af1f0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97327b20>\n",
      "[step:       7000] saved validator results to outputs\n",
      "[step:       7000] record validators time:  6.343e+00s\n",
      "[step:       7000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       7000] loss:  1.368e-04, time/iteration:  2.080e+02 ms\n",
      "[step:       7100] loss:  4.298e-04, time/iteration:  1.314e+02 ms\n",
      "[step:       7200] loss:  2.128e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       7300] loss:  3.000e-04, time/iteration:  1.313e+02 ms\n",
      "[step:       7400] loss:  2.190e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       7500] loss:  1.516e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       7600] loss:  3.736e-04, time/iteration:  1.313e+02 ms\n",
      "[step:       7700] loss:  2.402e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       7800] loss:  1.646e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       7900] loss:  1.820e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       8000] saved constraint results to outputs\n",
      "[step:       8000] record constraint batch time:  1.322e-01s\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbeaf5ea430>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe971622e0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe970da2e0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96fc0a90>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe97014280>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96ec4790>\n",
      "[step:       8000] saved validator results to outputs\n",
      "[step:       8000] record validators time:  6.500e+00s\n",
      "[step:       8000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       8000] loss:  3.037e-04, time/iteration:  2.112e+02 ms\n",
      "[step:       8100] loss:  1.809e-04, time/iteration:  1.333e+02 ms\n",
      "[step:       8200] loss:  1.386e-04, time/iteration:  1.333e+02 ms\n",
      "[step:       8300] loss:  1.785e-04, time/iteration:  1.328e+02 ms\n",
      "[step:       8400] loss:  1.950e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       8500] loss:  1.656e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       8600] loss:  2.127e-04, time/iteration:  1.312e+02 ms\n",
      "[step:       8700] loss:  2.441e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       8800] loss:  2.048e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       8900] loss:  1.645e-04, time/iteration:  1.311e+02 ms\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96d82220>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96d7d370>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96ce21f0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96c39dc0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96bb6910>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96b36ca0>\n",
      "[step:       9000] saved validator results to outputs\n",
      "[step:       9000] record validators time:  6.785e+00s\n",
      "[step:       9000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:       9000] loss:  1.344e-04, time/iteration:  2.128e+02 ms\n",
      "[step:       9100] loss:  2.170e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       9200] loss:  2.581e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       9300] loss:  1.452e-04, time/iteration:  1.307e+02 ms\n",
      "[step:       9400] loss:  2.185e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       9500] loss:  1.377e-04, time/iteration:  1.309e+02 ms\n",
      "[step:       9600] loss:  2.338e-04, time/iteration:  1.310e+02 ms\n",
      "[step:       9700] loss:  2.653e-04, time/iteration:  1.311e+02 ms\n",
      "[step:       9800] loss:  1.836e-04, time/iteration:  1.308e+02 ms\n",
      "[step:       9900] loss:  1.360e-04, time/iteration:  1.310e+02 ms\n",
      "[step:      10000] saved constraint results to outputs\n",
      "[step:      10000] record constraint batch time:  1.312e-01s\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96989760>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe969018b0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe968fb820>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe967e6df0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe96818ca0>\n",
      "locator: <matplotlib.ticker.AutoLocator object at 0x7fbe966e7be0>\n",
      "[step:      10000] saved validator results to outputs\n",
      "[step:      10000] record validators time:  6.457e+00s\n",
      "[step:      10000] saved checkpoint to /examples/workspace_0.5/modulus_documentation/modulus/docs/user_guide/basics/outputs\n",
      "[step:      10000] loss:  1.421e-04, time/iteration:  2.102e+02 ms\n",
      "[step:      10000] reached maximum training steps, finished training!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from modulus.sym.solver import Solver\n",
    "\n",
    "# optional\n",
    "# set appropriate GPU in case of multi-GPU machine\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "# make solver\n",
    "slv = Solver(cfg, ldc_domain)\n",
    "\n",
    "# start solver\n",
    "slv.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb826b8e",
   "metadata": {},
   "source": [
    "### Results and Post Processing\n",
    "\n",
    "#### Setting up Tensorboard\n",
    "\n",
    "[Tensorboard](https://www.tensorflow.org/tensorboard) is a great tool for visualization of machine learning experiments. To visualize the various training and validation losses, Tensorboard can be set up as follows:\n",
    "\n",
    "1. In a separate terminal window, navigate to the working directory of the example (eg. ``examples/ldc/``)\n",
    "\n",
    "2. Type in the following command on the command line. Specify the port you want to use. This example uses ``7007``. Once running, the command prompt shows the url that you will use to display the results.\n",
    "\n",
    "    ```bash\n",
    "    tensorboard --logdir=./ --port=7007\n",
    "    ```\n",
    "\n",
    "3. To view results, open a web browser and go to the url shown by the command prompt. An example would be: `http://localhost:7007/#scalars`. A window similar to shown below should open up in the browser window.\n",
    "\n",
    "The Tensorboard window displays the various losses at each step during the training. The `AdamOptimizer` loss is the total loss computed by the network. The `loss_continuity`, `loss_momentum_x` and `loss_momentum_y` determine the loss computed for the continuity and Navier-Stokes equations in the $x$ and $y$ directions, respectively. The `loss_u`\n",
    "and `loss_v` determine how well the boundary conditions are satisfied (soft constraints).\n",
    "\n",
    "<center>\n",
    "    <img src=\"../../images/user_guide/tensorboard_sample.png\" width=\"1200\" style=\"margin:auto\"/>\n",
    "    <figcaption>Tensorboard Interface</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb0ad3",
   "metadata": {},
   "source": [
    "#### Output Files\n",
    "\n",
    "The checkpoint directory is saved based on the results recording frequency specified as the ``'rec_results_freq'`` configuration option. The network directory folder\n",
    "(in this case ``'outputs/'``) contains the following important files/directories.\n",
    "\n",
    "1. ``optim_checkpoint.pth``, ``flow_network.pth``: Optimizer checkpoint and flow network saved during training.\n",
    "\n",
    "2. ``constraints``: This directory contains the data computed on the points added to the domain using ``add_constraint()``. The data are stored as ``.vtp`` files, which can be viewed using visualization tools like Paraview. You will see the true and predicted values of all the nodes that were passed to the ``nodes`` argument of the constraint. For example, the ``./constraints/Interior.vtp`` will have the variables for ``pred_continuity`` and ``true_continuity`` representing the network predicted and the true value set for ``continuity``. Below figure shows the comparison between true and computed continuity. This directory is useful to see how well the boundary conditions and equations are being satisfied at the sampled points.\n",
    "\n",
    "<center>\n",
    "    <img src=\"../../images/user_guide/train_continuity.png\" width=\"1000\" style=\"margin:auto\"/>\n",
    "    <figcaption>Visualization using Paraview. Left: Continuity as specified in the domain definition. Right: Computed continuity after training</figcaption>\n",
    "</center>\n",
    "\n",
    "3. ``validators:`` This directory contains the data computed on the points added in the domain using ``add_validator()``. This domain is more useful for validating the data with respect to a reference solution.  The data are stored as ``.vtp`` and ``.npz`` files (based on the ``save_filetypes`` configuration option). The ``.vtp`` files can be viewed using visualization tools like Paraview. The ``.vtp`` and ``.npz`` files in this directory will report predicted, true (validation data), pred (model's inference) on the chosen points. For example, the ``./validators/validator.vtp`` contains variables like ``true_u``, ``true_v``, ``true_p``, and ``pred_u``, ``pred_v``, ``pred_p`` corresponding to the true and the network predicted values for the variables $u$, $y$, and $p$.  \n",
    "\n",
    "<center>\n",
    "    <img src=\"../../images/user_guide/val_vs_train.png\" width=\"1200\" style=\"margin:auto\"/>\n",
    "    <figcaption>Comparison with OpenFOAM results</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc3e4b",
   "metadata": {},
   "source": [
    "### Extra: Adding Monitors and Inferencers\n",
    "\n",
    "#### Monitor Node\n",
    "\n",
    "Modulus Sym allows you to monitor desired quantities by plotting them every fixed number of iterations in Tensorboard as the simulation progresses, and analyze convergence based on the relative changes in the monitored quantities. A ``PointwiseMonitor`` can be used to create such an feature. Examples of such quantities can be point values of variables,\n",
    "surface averages, volume averages or any derived quantities that can be formed using the variables being solved.\n",
    "\n",
    "The flow variables are available as PyTorch tensors. You can perform tensor operations to create any desired derived variable of your choice. The code below shows the monitors for continuity and momentum imbalance in the interior.\n",
    "\n",
    "The points to sample can be selected using the ``sample_interior`` and ``sample_boundary`` methods.\n",
    "\n",
    "```python\n",
    "# add monitors\n",
    "global_monitor = PointwiseMonitor(\n",
    "    rec.sample_interior(4000, bounds={x: (-width/2, width/2), y: (-height/2, height/2)}),\n",
    "    output_names=[\"continuity\", \"momentum_x\", \"momentum_y\"],\n",
    "    metrics={\n",
    "        \"mass_imbalance\": lambda var: torch.sum(\n",
    "            var[\"area\"] * torch.abs(var[\"continuity\"])\n",
    "        ),\n",
    "        \"momentum_imbalance\": lambda var: torch.sum(\n",
    "            var[\"area\"]\n",
    "            * (torch.abs(var[\"momentum_x\"]) + torch.abs(var[\"momentum_y\"]))\n",
    "        ),\n",
    "    },\n",
    "    nodes=nodes,\n",
    ")\n",
    "ldc_domain.add_monitor(global_monitor)\n",
    "```\n",
    "\n",
    "<center>\n",
    "    <img src=\"../../images/user_guide/ldc_monitors.png\" width=\"800\" style=\"margin:auto\"/>\n",
    "    <figcaption>LDC Monitors in Tensorboard</figcaption>\n",
    "</center>\n",
    "\n",
    "#### Inferencer Node\n",
    "\n",
    "Modulus Sym also allows you to plot the results on arbitrary domains. You can then monitor these domains in Paraview or Tensorboard itself. The code below shows use of ``PointwiseInferencer``.\n",
    "\n",
    "```python\n",
    "# add inferencer data\n",
    "grid_inference = PointwiseInferencer(\n",
    "    nodes=nodes,\n",
    "    invar=openfoam_invar_numpy,\n",
    "    output_names=[\"u\", \"v\", \"p\"],\n",
    "    batch_size=1024,\n",
    "    plotter=InferencerPlotter(),\n",
    ")\n",
    "ldc_domain.add_inferencer(grid_inference, \"inf_data\")\n",
    "# add inferencer data\n",
    "grid_inference = PointwiseInferencer(\n",
    "    nodes=nodes,\n",
    "    invar=openfoam_invar_numpy,\n",
    "    output_names=[\"u\", \"v\", \"p\"],\n",
    "    batch_size=1024,\n",
    "    plotter=InferencerPlotter(),\n",
    ")\n",
    "ldc_domain.add_inferencer(grid_inference, \"inf_data\")\n",
    "```\n",
    "\n",
    "<center>\n",
    "    <img src=\"../../images/user_guide/ldc_inferencer.png\" width=\"800\" style=\"margin:auto\"/>\n",
    "    <figcaption>LDC Inferencer in Tensorboard</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15425e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
